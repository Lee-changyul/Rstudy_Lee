
1. 데이터 마이닝 기초 

1) 데이터의 활용 

* 통계 

  * 표본데이터를 이용하여 모집단에 대하여 추론
  *  예) 대통령 선거 유권자 조사해서 당선자 예측

* 기계학습(컴퓨터 공학)

  * 전체데이터를 이용해 개별값 예측
  * 기존 데이터로 모델을 학습시킨 후 새로운 데이터를 입력했을 때 예측값을 알아내기 위한 목적 
  * 알고리즘을 만드는 것
  *  예) 빅데이터 : 몇 천만개의 데이터를 통해서 분석, 이용자들의 데이터가 빅데이터가 됨 

* 데이터 마이닝(경영)

  * 통계 + 기계학습
  *  가지고 있는 데이터에서 일정한 패턴이나 특성을 발견 -> 개별값 예측 
  *  기계학습에 가깝지만 응용부분 (문제해결을 위한 방법이 중요)
  *  데이터를 주고 규칙을 전문가가 찾아내는 것 

 => 향후에는 데이터를 기계에게 주면 기계가 스스로 분석하여  결과를 만들어 내는 것 : 딥러닝 

2) 빅데이터 처리과정 

 - 데이터 소스 => 수집(수동, 자동(크롤링, 로그수집기, 센싱) => 저장(정형, 비정형 데이터 등) 
   => 처리 (일괄처리, 실시간처리, 분산병렬 처리 등) => 분석(전처리, 분석) => 표현

3) 데이터마이닝의 목적 

- 분류(범주형)와 예측(연속형 자료) 
  => 두 가지 중에 어떤 것을 쓸까? 모델을 비교하여 성능에 따라 선택함
  => 목적에 따라 선호하는 방법론이 있다. 

* 데이터 마이닝의 로드맵(ppt 26, 28쪽)

 - 지도학습(결과가 정해져 있는 것을 가지고 분석) : 예측(선형회귀, 회귀나무, 신경망, 앙상블) - 결과가 값을 가질 경우 / 분류(베이즈, 분류나무(의사결정 나무), 신경망, 로지스틱 회귀) - 결과가 범주형으로 정해짐 / 시계열 예측

  =>  얼마나 잘 맞췄는지를 평가하기 위해서 모델에 대한 성능평가가 중요함 

 - 비지도학습(데이터의 관계 분석) : 레코드 관계 마이닝(연관규칙, 협업 필터링), 분할(군집분석, 협업필터링), 데이터 애널리틱스(비정형화된 데이터 마이닝 - 사회연결망, 텍스트마이닝)

 ==========

2. 의사결정 나무(분류나무)

 - 분류나무 : 목표 변수가 범주형 변수 -> 분류
 - 회귀나무 : 목표 변수가 수치형 변수 -> 예측
 - 앙상블 

1) 의사결정나무 : 설명하기에 좋음(성능이 떨어지더라도)

 - 목표 : 예측변수를 기반으로 결과를 분류하거나 예측
 - 의사결정 규칙(decision rule)을 나무구조(tree)로 도표화하여 분류(classification)와 예측(prediction)을 수행하는 분석방법
  * 분류 : 남자일지, 여자일지, 물건을 살지, 안살지 등 확인
 
 - 나무의 성장과 가지치기가 핵심 
  예) 은행고객 대출 제안 수락 여부 
   = 목표 : 어느 고객이 대출제안을 수락(yes)/거절(no) 할지를 분류
   = 규칙 : 가장 가능성이 높은 것부터 탐색 하여 가지치기 실행 

2) 주요방법

 - Tree and Rule 구조 
  * 규칙은 나무모델(tree diagrams)로 표현
  * 결과는 규칙으로 표현

- 재귀적 분할 (Recursive partitioning)
  * 나무 만드는 과정 
  * 그룹이 최대한 동질하도록 반복적으로 레코드를 하위 그룹으로 분리 (yes, no 가 한 그룹에 다 묶일 수 있도록)

- 가지치기(Pruning the tree) : 두 가지 방법 
  * 생성된 나무를 자르는 과정(정교화) : 중간에 자름 
  * 과적합을 피하기 위해 필요없는 가지를 간단히 정리 : 다 성장시킨 후 가지치기(많이 사용)

3) 적용분야

 - 은행대출, 카드발급대상, 의료시스템, 이탈고객분류 : 사유를 설명하기 위해서 


4) 주요 용어 

뿌리노드(root node)
부모노드(parent node)
자식노드(child node)
단말노드(terminal node) : 단말 노드를 최대한 쪼개서 잘 맞추는 것이 목표 


5) 구분 : 분류와 회귀

 - 재귀적 분할 알고리즘
 * CART(Classification And Regressin Tree) : 분류와 예측 모두 가능, 옵션 조정
 * C 5.0
 * CHIAD(Chi-square Automatic Interation Detection)

 - 불순도(Impurity) 알고리즘 : 나무성장과정에서 사용하는 지수 
 * 서로 연결되어 있어서 설명을 이해하고 가는 것이 중요하다. 

 * 지니 지수(Gini index)
 * 엔트로피 지수(Entropy index), 정보 이익(Information Gain)
 * 카이제곱 통계량(Chi-Square statistic)

6) 구분 : 분류 나무(Classification Tree) 

- 분류 알고리즘과 불순수도 지표 연결 
 * CART : 지니 지수(Gini index)
 * C4.5 : 엔트로피(Entropy index), 정보이익(Information gain), 정보이익비율(Information gain ratio)
 * CHAID : 카이제곱 통계량 (Chi - Square statistic)

7) 분류 : 회귀나무(Regression Tree)
- 분류 알고리즙과 불순수도 지표 연결
 * CART : F통계량 - 분산의 감소량 
  => 끝마디로 평균을 이용함 (실제값과 예측값과의 평균차이가 적은 방식으로 계속 분류해 나간다는 의미)
 * 예측일 경우 이보다는 신경망, 회귀분석이 많이 사용됨 

8) 의사결정나무 분리기준 : 분류 알고리즘에 따라서 기준이 달라진다. ppt 13쪽이 중요 

- 이지 분리(binary split) : CART 
- 다지 분리(multi - way split) : CHIAD, C4.5, C5.0 ---


